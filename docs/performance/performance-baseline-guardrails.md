# Performance Baseline Guardrails

This note tracks how we collect, retain, and interpret the performance baseline artifacts
generated by `npm run telemetry:performance:baseline`. The script aggregates five fresh
snapshots from `performanceSnapshot.js` and writes an aggregate JSON report that CI now
publishes alongside other telemetry.

## Latest Baseline (Session 87 warm-up fix)

- **Artifact**: `telemetry-artifacts/performance/ci-baseline.json`
- **Generated at**: 2025-10-30T02:19:47.904Z
- **Runs aggregated**: 5

| Metric            | Avg (ms) | Threshold (ms) | Utilisation | Status | Min / Max (ms) |
| ----------------- | -------- | -------------- | ----------- | ------ | -------------- |
| forensicAnalysis  | 0.0382   | 4              | 0.95%       | OK     | 0.0049 / 0.1813 |
| factionModify     | 0.0032   | 2              | 0.16%       | OK     | 0.0014 / 0.0087 |
| factionAttitude   | 0.0002   | 0.05           | 0.40%       | OK     | 0 / 0.0007 |
| bspGeneration     | 3.9976   | 10             | 39.98%      | OK     | 3.3874 / 5.2376 |

`performanceSnapshot.js` now performs a single BSP warm-up iteration before recording
samples, eliminating the JIT-related 12 ms spike that showed up in Session 86. All
metrics sit comfortably below their thresholds and no alerts fired on the latest run.

## Alerting Rules

Our `summarizePerformanceBaseline.js` helper (see usage below) evaluates every metric and
raises warnings when utilisation crosses 80% of the configured threshold or when peak
samples exceed the cap. If utilisation exceeds 95% or `performanceBaseline.js` marks the
metric as failed, the helper escalates the status to `CRITICAL`.

Alert matrix:

| Utilisation vs. threshold | Status    | Action                                                                 |
| ------------------------- | --------- | ---------------------------------------------------------------------- |
| < 80%                     | OK/INFO   | No action required                                                     |
| 80% - 94.99%              | WARNING   | Investigate regressions, plan follow-up optimisation                   |
| >= 95% or baseline failure | CRITICAL  | Block merging until metric recovers, raise `PERF-119` follow-up issue  |

To surface alerts locally, run:

```bash
npm run telemetry:performance:baseline -- --runs 5 --out telemetry-artifacts/performance/ci-baseline.json
node scripts/telemetry/postPerformanceSummary.js \
  telemetry-artifacts/performance/ci-baseline.json \
  telemetry-artifacts/performance/ci-baseline-summary.md
cp telemetry-artifacts/performance/ci-baseline-summary.md docs/performance/performance-baseline-latest.md
```

The helper prints a markdown table and writes it to the optional `--output` path so the
latest baseline can be reviewed quickly in pull requests or stored with build artifacts.

## Retention Policy

1. After each CI run, copy the generated `ci-baseline.json` into
   `telemetry-artifacts/performance/history/<ISO-DATE>-ci-baseline.json`.
2. Keep the last **14** baseline aggregates (roughly two weeks of CI history) inside the
   `history/` folder; prune older files during weekly maintenance.
3. When a warning or critical alert fires, attach the corresponding JSON and markdown
   summary to the `PERF-119` backlog item notes so trend analysis remains centralised.

The `history/` directory stays git-ignored to avoid polluting the repository. CI uploads
the same files to artifact storage for long-term retention.

## Future Automation

- CI now calls `postPerformanceSummary.js` after every baseline run so the job summary
  and uploaded artifacts always include markdown plus annotated warnings.
- Extend the summary step with delta analysis against the previous baseline once the
  history directory contains more than one entry.
